service: jobs

frameworkVersion: ">=1.1.0 <2.0.0"

plugins:
  - serverless-domain-manager
  - serverless-python-requirements
  - serverless-aws-documentation

provider:
  name: aws
  runtime: python3.6
  region: us-west-2

  # simple security based on stages and api keys
  # one fits all for production
  apiKeys:
    - "jobs-${self:custom.stage}"

  #required permissions
  iamRoleStatements:
    - Effect: Allow
      Action:
        - dynamodb:*
      Resource: "*"

    - Effect: Allow
      Action:
        - sqs:*
      Resource: { "Fn::Join": [":", ["arn:aws:sqs:${self:custom.region}",  "*:*" ] ]  }

    - Effect: Allow
      Action:
        - s3:*
      Resource: "arn:aws:s3:::*"
    - Effect: "Allow"
      Action:
        - ecs:RunTask
        - ecs:ListTasks
      Resource: "*"
    - Effect: Allow
      Action:
        - iam:PassRole
      Resource: "*"



  memorySize: 128
  timeout: 90
  versionFunctions: false

  logRetentionInDays: 3

  #where to store out data, needs to be manually created!
  deploymentBucket:
    name: "lambdas-jobs"

############################################################################################
#custom configuration settings
############################################################################################
custom:
  stage: ${opt:stage, self:provider.stage}
  region: ${opt:region, self:provider.region}

  ###
  # resources definitions
  ###
  trackingTable: "JobsTrackingTable-${self:custom.stage}"

  stasisTrackingTable: "JobsTrackingTable-${self:custom.stage}"

  ###
  # this is the queue which contains all the tasks to be executed during the scheduling phase of the process
  ###
  scheduleQueue: "JobsScheduleQueue-${self:custom.stage}"

  ###
  # this queue will take care of holding all pending aggregation tasks
  aggregationQueue: "JobsAggregationQueue-${self:custom.stage}"

  ##
  # defined queue to send jobs to stasis fargate for processing
  processingQueue: "StasisScheduleQueue-${self:custom.stage}"

  ###
  # custom domain management
  ###

  domains:
    prod: api.metabolomics.us
    test: test-api.metabolomics.us
    dev:  dev-api.metabolomics.us

  customDomain:
    basePath: "jobs"
    domainName: ${self:custom.domains.${self:custom.stage}}
    stage: "${self:custom.stage}"
    createRoute53Record: true

  pythonRequirements:
    dockerizePip: true
    slim: true
    noDeploy:
      - "boto3"
      - "botocore"
      - "moto"
      - "pytest"

  documentation:
    api:
      info:
        version: '1'
        title: 'LC BinBase Scheduler Server'
        description: 'AWS powered interface to the AWS based schedule server'
        contact:
          name: Gert Wohlgemuth
          email: wohlgemuth@ucdavis.edu
        license:
          name: LGPL3
          url: https://www.gnu.org/licenses/lgpl-3.0.en.html

############################################################################################
# this section defines what to include and exclud when packaging artifacts
############################################################################################
package:
  exclude:
    - .git/**
    - .venv/**
    - .idea/**
    - .pytest_cache/**
    - venv/**
    - test/**
    - tests/**
    - node_modules/**
    - integrationTests/**

############################################################################################
# this section defines all lambda function and triggers
############################################################################################
functions:

  #creates a new tracking record in the system
  trackingCreate:
    handler: jobs/tracking.create
    events:
      - http:
          path: tracking
          private: true
          method: post
          cors: true
          documentation:
            summary: updates the tracking status of a sample with the associated job

    #defines to which topic we want to connect
    environment:
      trackingTable: ${self:custom.trackingTable}

  #fetches an existing tracking record from the system
  trackingGet:
    handler: jobs/tracking.get
    events:
      - http:
          documentation:
            summary: Returns the tacking status of a sample with an associated job
            queryParams:
              - name: job
                description: the job id
                required: true
              - name: sample
                description: the sample id
                required: true

          path: tracking/{job}/{sample}
          private: true
          method: get
          cors: true
          request:
            parameter:
              paths:
                job: true
                sample: true

    #defines to which topic we want to connect
    environment:
      trackingTable: ${self:custom.trackingTable}

  # computes the current state of the given job
  trackingStatus:
    handler: job/tracking.status
    events:
      - http:
          path: job/status/{job}
          private: true
          method: get
          cors: true
          request:
            parameter:
              paths:
                job: true
          documentation:
            summary: returns the overal status of the given job
            queryParams:
              - name: job
                description: the job id
                required: true

    #defines to which topic we want to connect
    environment:
      trackingTable: ${self:custom.trackingTable}

  # computes the complete job
  job:
    handler: job/tracking.description
    events:
      - http:
          path: job/{job}
          private: true
          method: get
          cors: true
          request:
            parameter:
              paths:
                job: true
          documentation:
            summary: return the complete job description with all associated samples and there states
            queryParams:
              - name: job
                description: the job id
                required: true

    #defines to which topic we want to connect
    environment:
      trackingTable: ${self:custom.trackingTable}

  #schedule data to for handling the processing and aggregation on the backend
  schedule:
    handler: jobs/schedule.schedule
    events:
      - http:
          path: schedule
          method: post
          private: true
          cors: true
          documentation:
            summary: schedules a job to be computed to the backend queue

    #defines to which topic we want to connect
    environment:

      ##
      # contains scheduling events
      schedule_queue: ${self:custom.scheduleQueue}

      ##
      # contains aggregation events
      aggregation_queue: ${self:custom.aggregationQueue}

      ##
      # contains processing events
      processing_queue: ${self:custom.processingQueue}


